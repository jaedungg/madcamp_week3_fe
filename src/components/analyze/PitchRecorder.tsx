'use client';

import { use, useEffect, useRef, useState } from 'react';
import { detectPitch } from '@/lib/util/pitchUtils'; // ì˜¤í† ì½”ë¦´ë ˆì´ì…˜ pitch detection í•¨ìˆ˜
import { Button, Card, Collapse, Progress, Typography } from 'antd';
import { Chart, registerables } from 'chart.js';

Chart.register(...registerables);

const { Text } = Typography;

interface PitchRecorderProps {
  uuid: string | null;
  audioUrl: string | null;
}

export default function PitchRecorder({uuid, audioUrl} : PitchRecorderProps) {
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const chartRef = useRef<Chart | null>(null);

  // ì‹¤ì‹œê°„ ë°ì´í„° ì¶”ì ìš© ref
  const pitchDataRef = useRef<(number | null)[]>([]);
  const timeStampsRef = useRef<number[]>([]);
  const tickRef = useRef(0);
  const isRecordingRef = useRef(false);
  // ì˜¤ë””ì˜¤ ì¬ìƒ
  const audioRef = useRef<HTMLAudioElement | null>(null);
  // ê°€ì‚¬ í‘œì‹œ
  const [currentLyric, setCurrentLyric] = useState<string>('');
  const lyricsRef = useRef<{ start: number; duration: number; text: string }[]>([]);

  const [isRecording, setIsRecording] = useState(false);
  const [pitchData, setPitchData] = useState<(number | null)[]>([]);
  const [originalPitch, setOriginalPitch] = useState<(number | null)[]>([]);
  const [timeStamps, setTimeStamps] = useState<number[]>([]);
  const [analyzed, setAnalyzed] = useState(false);
  const [feedback, setFeedback] = useState<string[]>([]);

  // Chart ì´ˆê¸°í™”
  useEffect(() => {
    if (canvasRef.current && !chartRef.current) {
      const ctx = canvasRef.current.getContext('2d');
      if (ctx) {
        chartRef.current = new Chart(ctx, {
          type: 'line',
          data: {
            labels: [],
            datasets: [
              {
                label: 'Live Pitch (Hz)',
                data: [],
                borderColor: 'blue',
                fill: false,
                pointRadius: 0,
              },
              {
                label: 'Original Pitch (Hz)',
                data: [],
                borderColor: 'orange',
                fill: false,
                pointRadius: 0,
              },
            ],
          },
          options: {
            animation: false,
            responsive: true,
            scales: {
              x: {
                title: { display: true, text: 'Time (ms)' },
              },
              y: {
                title: { display: true, text: 'Pitch (Hz)' },
                min: 0,
                max: 1500,
              },
            },
          },
        });
      }
    }
  }, []);

  const updateChart = (labels: number[], liveData: (number | null)[]) => {
    if (!chartRef.current) return;

    // ê·¸ë˜í”„ ìŠ¤ì¼€ì¼ë§
    // const now = audioRef.current?.currentTime ?? 0;
    // const minX = now * 1000 - 1000;
    // const maxX = now * 1000 + 5000;
    const nowTick = tickRef.current;
    const minX = nowTick - 10000;
    const maxX = nowTick + 50000;

    chartRef.current.data.labels = labels;
    chartRef.current.data.datasets[0].data = liveData;
  
    // ì›ê³¡ pitch ê¸¸ì´ê°€ liveDataë³´ë‹¤ ì§§ìœ¼ë©´ ë‚˜ë¨¸ì§€ëŠ” nullë¡œ ì±„ìš°ê¸°
    const originalData = [...originalPitch];
    while (originalData.length < labels.length) {
      originalData.push(null);
    }
    chartRef.current.data.datasets[1].data = originalData;
    
    // ê·¸ë˜í”„ ìŠ¤ì¼€ì¼ë§
    chartRef.current.options!.scales!.x!.min = minX;
    chartRef.current.options!.scales!.x!.max = maxX;
  
    chartRef.current.update('none');
  };

  const handleRecord = async () => {
    if (isRecording) {
      // ë…¹ìŒ ì¢…ë£Œ
      setIsRecording(false);
      isRecordingRef.current = false;

      // ì˜¤ë””ì˜¤ ì •ì§€
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
      }
      
      // ë¶„ì„ìš© ìƒíƒœì— ë³µì‚¬
      setPitchData([...pitchDataRef.current]);
      setTimeStamps([...timeStampsRef.current]);
      
      analyzePitch();
      return;
    }
    
    // ì´ˆê¸°í™”
    pitchDataRef.current = [];
    timeStampsRef.current = [];
    tickRef.current = 0;
    setAnalyzed(false);
    setFeedback([]);
    setIsRecording(true);
    isRecordingRef.current = true;

    // ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘
    if (audioRef.current) {
      audioRef.current.currentTime = 0;
      audioRef.current.play().catch((err) => {
        console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', err);
      });
    }
    
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    source.connect(analyser);
    
    const buffer = new Float32Array(analyser.fftSize);
    
    const loop = () => {
      if (!isRecordingRef.current) {
        audioContext.close();
        return;
      }
      
      analyser.getFloatTimeDomainData(buffer);
      const pitch = detectPitch(buffer, audioContext.sampleRate);
      
      pitchDataRef.current.push(pitch ?? null);
      timeStampsRef.current.push(tickRef.current);
      updateChart(timeStampsRef.current, pitchDataRef.current);
      
      tickRef.current += 50;
      requestAnimationFrame(loop);
    };
    
    loop();
  };

  const analyzePitch = () => {
    const cleaned = pitchDataRef.current.filter(
      (p) => p !== null && p > 50 && p < 800
    ) as number[];
    const average =
    cleaned.reduce((a, b) => a + b, 0) / cleaned.length || 0;
    const variance =
    cleaned.reduce((acc, p) => acc + Math.pow(p - average, 2), 0) /
    cleaned.length || 0;
    
    const result: string[] = [];
    if (average > 500)
      result.push('âš ï¸ ì „ë°˜ì ìœ¼ë¡œ ê³ ìŒ ìœ„ì£¼ì…ë‹ˆë‹¤. ì•ˆì •ì ì¸ ë°œì„±ì´ í•„ìš”í•´ìš”.');
    if (variance > 2000)
      result.push('ğŸ¯ ìŒì • í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤. ë°œì„±ì˜ ì¼ê´€ì„±ì„ ì—°ìŠµí•´ë³´ì„¸ìš”.');
    if (average < 200)
      result.push('ğŸ“‰ ìŒì •ì´ ë‚®ì€ í¸ì…ë‹ˆë‹¤. ë” ì •í™•í•œ ìŒì •ì„ ê²¨ëƒ¥í•´ë³´ì„¸ìš”.');
    
    setFeedback(result);
    setAnalyzed(true);
  };

  console.log('PitchRecorder mounted with uuid:', uuid, 'audioUrl:', audioUrl);

  const fetchAudioData = async () => {
    const response = await fetch('/api/music_meta/' + uuid, {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
      },
    });
    if (!response.ok) {
      throw new Error('Failed to fetch audio data');
    }
    const data = await response.json();
    return data;
  };

  useEffect(() => {
    if (uuid && audioUrl) {
      console.log('Fetching audio data for uuid:', uuid);
      fetchAudioData()
        .then((data) => {
          console.log('Audio data fetched: ', data);
          lyricsRef.current = JSON.parse(data.lyrics);
          setOriginalPitch(data.pitch_vector.slice(0));
        })
        .catch((error) => {
          console.error('Error fetching audio data:', error);
        });
    }
  }, [uuid, audioUrl]);

  // í˜„ì¬ ì˜¤ë””ì˜¤ ì‹œê°„ì— ë§ì¶° ê°€ì‚¬ ì—…ë°ì´íŠ¸
  useEffect(() => {
    const interval = setInterval(() => {
      if (!audioRef.current) return;
  
      const currentTime = audioRef.current.currentTime;
      const current = lyricsRef.current.find(
        (line) =>
          currentTime >= line.start &&
          currentTime <= line.start + line.duration
      );
  
      setCurrentLyric(current?.text ?? '');
    }, 100); // 100ms ë‹¨ìœ„ë¡œ í™•ì¸
  
    return () => clearInterval(interval);
  }, []);

  return (
    <div>
      <h1 className='text-xl font-bold mb-4'>ğŸ¼ ì‹¤ì‹œê°„ í”¼ì¹˜ ë¶„ì„ê¸°</h1>
      <audio ref={audioRef} src={audioUrl ?? undefined} />

      <div className='w-[80%] mx-auto mb-4'>
        <canvas
          ref={canvasRef}
          width={600}
          height={300}
          style={{ marginTop: '20px', border: '1px solid #ccc' }}
        />
      </div>

      {currentLyric && (
        <div> 
        {/* <div 
        className="text-center my-4 text-2xl font-bold transition-all duration-200 animate-pulse text-white drop-shadow-lg drop-shadow-indigo-500">
          {currentLyric}
        </div>  */}
        <h1
          className="text-center my-4 text-2xl font-bold text-white drop-shadow-sm drop-shadow-indigo-500"
          style={{
            textShadow: `-1px -1px 0 #6366F1,
                         1px -1px 0 #6366F1,
                        -1px  1px 0 #6366F1,
                         1px  1px 0 #6366F1`
          }}
        >
          {currentLyric}
        </h1>
        </div>
        
      )}

      <button 
        className={`flex flex-1 items-center bg-indigo-400 justify-center p-3 px-4 rounded-lg text-lg text-white transition cursor-pointer`}
        onClick={handleRecord}>
        {isRecording ? 'ë…¹ìŒ ì¢…ë£Œ & ë¶„ì„' : 'ğŸ™ ì‹¤ì‹œê°„ í”¼ì¹˜ ë…¹ìŒ'}
      </button>

      {analyzed && (
        <Card title="AI ë¶„ì„ ë¦¬í¬íŠ¸" style={{ marginTop: 24 }}>
          <Progress
            percent={Math.min(100, Math.round(100 - feedback.length * 20))}
          />
          <Collapse
            defaultActiveKey={['1']}
            style={{ marginTop: 16 }}
            items={[
              {
                key: '1',
                label: 'í”¼ë“œë°± ìš”ì•½',
                children:
                  feedback.length > 0 ? (
                    feedback.map((line, idx) => (
                      <Text key={idx}>{line}</Text>
                    ))
                  ) : (
                    <Text type="success">
                      ğŸ‘ ì•ˆì •ì ì¸ í”¼ì¹˜ ìœ ì§€! í›Œë¥­í•©ë‹ˆë‹¤.
                    </Text>
                  ),
              },
            ]}
          />
        </Card>
      )}
    </div>
  );
}
