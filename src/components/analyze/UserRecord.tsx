'use client';

import { Dispatch, SetStateAction, use, useEffect, useRef, useState } from 'react';
import { detectPitch } from '@/lib/util/pitchUtils'; // ì˜¤í† ì½”ë¦´ë ˆì´ì…˜ pitch detection í•¨ìˆ˜
import { Button, Card, Collapse, Progress, Typography } from 'antd';
import { Chart, registerables } from 'chart.js';

Chart.register(...registerables);

const { Text } = Typography;

interface UserRecordProps {
  uuid: string | null;
  audioUrl: string | null;
  userAudioUrl: string | null;
  setUserAudioUrl: Dispatch<SetStateAction<string | null>>;
}

export default function UserRecord({uuid, audioUrl, userAudioUrl} : UserRecordProps) {
  // ì˜¤ë””ì˜¤ ì¬ìƒ
  const audioRef = useRef<HTMLAudioElement | null>(null);
  // ê°€ì‚¬ í‘œì‹œ
  const [currentLyric, setCurrentLyric] = useState<string>('');
  const lyricsRef = useRef<{ start: number; duration: number; text: string }[]>([]);
  // ìœ ì € ë…¸ë˜ ë…¹ìŒ
  const recordedChunksRef = useRef<Blob[]>([]);
  const [echoedAudioUrl, setEchoedAudioUrl] = useState<string | null>(null);  

  const [userRecordPlaying, setUserRecordPlaying] = useState(false);
  const [echoedRecordPlaying, setEchoedRecordPlaying] = useState(false);

  const mrAudioRef = useRef<HTMLAudioElement | null>(null);
  const userAudioRef = useRef<HTMLAudioElement | null>(null);
  const echoedAudioRef = useRef<HTMLAudioElement | null>(null);

  const playMergedAudio = () => {
    if (!audioUrl || !userAudioUrl) return;

    if (mrAudioRef.current && userAudioRef.current) {
      // ì •ì§€
      setUserRecordPlaying(false);
      mrAudioRef.current.pause();
      mrAudioRef.current.currentTime = 0;
      userAudioRef.current.pause();
      userAudioRef.current.currentTime = 0;
      mrAudioRef.current = null;
      userAudioRef.current = null;
      return;
    }
  
    // ì¬ìƒ
    setUserRecordPlaying(true);
    const mrAudio = new Audio(audioUrl);
    const userAudio = new Audio(userAudioUrl);
    mrAudio.volume = 0.6;
    userAudio.volume = 1.0;
  
    mrAudio.play();
    userAudio.play();
  
    mrAudioRef.current = mrAudio;
    userAudioRef.current = userAudio;
  };

  const handleAddEcho = async () => {
    if (!userAudioUrl) return;
  
    try {
      // fetchë¥¼ í†µí•´ Blob ìƒì„±
      const audioResponse = await fetch(userAudioUrl);
      const audioBlob = await audioResponse.blob();
  
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      formData.append('delay', '250'); // ms
      formData.append('repeat', '3');
      formData.append('decay', '0.5');
  
      const res = await fetch('http://172.20.12.58:80/add_echo', {
        method: 'POST',
        body: formData,
      });

      console.log("res status", res.status);
      console.log("res", res);
  
      if (res.ok) {
        const echoedBlob = await res.blob();
        const url = URL.createObjectURL(echoedBlob);
        setEchoedAudioUrl(url);
      } else {
        alert('ì—ì½” ì¶”ê°€ ì‹¤íŒ¨');
      }
    } catch (err) {
      console.error('ì—ì½” ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', err);
      alert('ì—ì½” ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  };
  

  const playMergedEchoed = () => {
    if (!audioUrl || !echoedAudioUrl) return;

    if (mrAudioRef.current && echoedAudioRef.current) {
      // ì •ì§€
      setEchoedRecordPlaying(false);
      mrAudioRef.current.pause();
      mrAudioRef.current.currentTime = 0;
      echoedAudioRef.current.pause();
      echoedAudioRef.current.currentTime = 0;
      mrAudioRef.current = null;
      echoedAudioRef.current = null;
      return;
    }
  
    setEchoedRecordPlaying(true);
    const mrAudio = new Audio(audioUrl);
    const echoAudio = new Audio(echoedAudioUrl);
    mrAudio.volume = 0.6;
    echoAudio.volume = 1.0;
  
    mrAudio.play();
    echoAudio.play();
  
    mrAudioRef.current = mrAudio;
    echoedAudioRef.current = echoAudio;
  };

  // const analyzePitch = () => {
  //   const cleaned = pitchDataRef.current.filter(
  //     (p) => p !== null && p > 50 && p < 800
  //   ) as number[];
  //   const average =
  //   cleaned.reduce((a, b) => a + b, 0) / cleaned.length || 0;
  //   const variance =
  //   cleaned.reduce((acc, p) => acc + Math.pow(p - average, 2), 0) /
  //   cleaned.length || 0;
    
  //   const result: string[] = [];
  //   if (average > 500)
  //     result.push('âš ï¸ ì „ë°˜ì ìœ¼ë¡œ ê³ ìŒ ìœ„ì£¼ì…ë‹ˆë‹¤. ì•ˆì •ì ì¸ ë°œì„±ì´ í•„ìš”í•´ìš”.');
  //   if (variance > 2000)
  //     result.push('ğŸ¯ ìŒì • í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤. ë°œì„±ì˜ ì¼ê´€ì„±ì„ ì—°ìŠµí•´ë³´ì„¸ìš”.');
  //   if (average < 200)
  //     result.push('ğŸ“‰ ìŒì •ì´ ë‚®ì€ í¸ì…ë‹ˆë‹¤. ë” ì •í™•í•œ ìŒì •ì„ ê²¨ëƒ¥í•´ë³´ì„¸ìš”.');
    
  //   setFeedback(result);
  //   setAnalyzed(true);
  // };

  console.log('UserRecord mounted with uuid:', uuid, 'audioUrl:', audioUrl);

  // í˜„ì¬ ì˜¤ë””ì˜¤ ì‹œê°„ì— ë§ì¶° ê°€ì‚¬ ì—…ë°ì´íŠ¸
  useEffect(() => {
    const interval = setInterval(() => {
      if (!audioRef.current) return;
  
      const currentTime = audioRef.current.currentTime;
      const current = lyricsRef.current.find(
        (line) =>
          currentTime >= line.start &&
          currentTime <= line.start + line.duration
      );
  
      setCurrentLyric(current?.text ?? '');
    }, 100); // 100ms ë‹¨ìœ„ë¡œ í™•ì¸
  
    return () => clearInterval(interval);
  }, []);

  return (
    <div>
      <h1 className='text-xl font-bold mb-4'>ğŸ¼ ìœ ì € ë…¹ìŒ í™•ì¸</h1>
      {userAudioUrl && (
        <div className="mt-4 flex gap-4">
          <button onClick={playMergedAudio} className="bg-blue-500 text-white px-4 py-2 rounded cursor-pointer">
            {userRecordPlaying? 'â¹ ì¬ìƒ ì •ì§€' : 'â–¶ï¸ MR + ë…¹ìŒ ì¬ìƒ'}
          </button>
          <button onClick={handleAddEcho} className="bg-indigo-500 text-white px-4 py-2 rounded cursor-pointer">
            âœ¨ ì—ì½” ì¶”ê°€
          </button>
        </div>
      )}

      {echoedAudioUrl && (
        <button onClick={playMergedEchoed} className="mt-2 bg-purple-600 text-white px-4 py-2 rounded">
          {echoedRecordPlaying ? 'â¹ ì •ì§€' : 'ğŸ§ ì—ì½” ìŒì„± + MR ì¬ìƒ'}
        </button>
      )}
    </div>
  );
}
