'use client';

import { Dispatch, SetStateAction, use, useEffect, useRef, useState } from 'react';
import { detectPitch } from '@/lib/util/pitchUtils'; // ì˜¤í† ì½”ë¦´ë ˆì´ì…˜ pitch detection í•¨ìˆ˜
import { Select, Button, Card, Collapse, Progress, Typography } from 'antd';
import { Chart, registerables } from 'chart.js';
import { SoundOutlined, PlayCircleOutlined, PauseCircleOutlined, RobotOutlined } from '@ant-design/icons';

Chart.register(...registerables);

const { Text } = Typography;

interface UserRecordProps {
  uuid: string | null;
  audioUrl: string | null;
  userAudioUrl: string | null;
  setUserAudioUrl: Dispatch<SetStateAction<string | null>>;
}

export default function UserRecord({uuid, audioUrl, userAudioUrl} : UserRecordProps) {
  const { Option } = Select;
  const { Title } = Typography;
  
  // ì˜¤ë””ì˜¤ ì¬ìƒ
  const audioRef = useRef<HTMLAudioElement | null>(null);
  // ê°€ì‚¬ í‘œì‹œ
  const [currentLyric, setCurrentLyric] = useState<string>('');
  const lyricsRef = useRef<{ start: number; duration: number; text: string }[]>([]);
  // ìœ ì € ë…¸ë˜ ë…¹ìŒ
  const recordedChunksRef = useRef<Blob[]>([]);
  const [echoedAudioUrl, setEchoedAudioUrl] = useState<string | null>(null);  
  const [tunedAudioUrl, setTunedAudioUrl] = useState<string | null>(null);  
  const [selectedEffect, setSelectedEffect] = useState<'echo' | 'autotune' | null>(null);
  const [loadingEffect, setLoadingEffect] = useState(false);

  const [userRecordPlaying, setUserRecordPlaying] = useState(false);
  const [echoedRecordPlaying, setEchoedRecordPlaying] = useState(false);
  const [tunedRecordPlaying, setTunedRecordPlaying] = useState(false);

  const mrAudioRef = useRef<HTMLAudioElement | null>(null);
  const userAudioRef = useRef<HTMLAudioElement | null>(null);
  const echoedAudioRef = useRef<HTMLAudioElement | null>(null);
  const tunedAudioRef = useRef<HTMLAudioElement | null>(null);

  const playMergedAudio = () => {
    if (!audioUrl || !userAudioUrl) return;

    if (mrAudioRef.current && userAudioRef.current) {
      // ì •ì§€
      setUserRecordPlaying(false);
      mrAudioRef.current.pause();
      mrAudioRef.current.currentTime = 0;
      userAudioRef.current.pause();
      userAudioRef.current.currentTime = 0;
      mrAudioRef.current = null;
      userAudioRef.current = null;
      return;
    }
  
    // ì¬ìƒ
    setUserRecordPlaying(true);
    const mrAudio = new Audio(audioUrl);
    const userAudio = new Audio(userAudioUrl);
    mrAudio.volume = 0.6;
    userAudio.volume = 1.0;
  
    mrAudio.play();
    userAudio.play();
  
    mrAudioRef.current = mrAudio;
    userAudioRef.current = userAudio;
  };

  const handleAddEcho = async () => {
    if (!userAudioUrl) return;
  
    try {
      // fetchë¥¼ í†µí•´ Blob ìƒì„±
      const audioResponse = await fetch(userAudioUrl);
      const audioBlob = await audioResponse.blob();
  
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      formData.append('delay', '250'); // ms
      formData.append('repeat', '3');
      formData.append('decay', '0.5');
  
      const res = await fetch('http://172.20.12.58:80/add_echo', {
        method: 'POST',
        body: formData,
      });

      console.log("res status", res.status);
      console.log("res", res);
  
      if (res.ok) {
        const echoedBlob = await res.blob();
        const url = URL.createObjectURL(echoedBlob);
        setEchoedAudioUrl(url);
      } else {
        alert('ì—ì½” ì¶”ê°€ ì‹¤íŒ¨');
      }
    } catch (err) {
      console.error('ì—ì½” ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', err);
      alert('ì—ì½” ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const handleAutoTune = async () => {
    if (!userAudioUrl || !uuid) {
      alert('ë…¹ìŒëœ íŒŒì¼ ë˜ëŠ” musicidê°€ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }
  
    try {
      // fetchë¥¼ í†µí•´ Blob ìƒì„±
      const audioResponse = await fetch(userAudioUrl);
      const audioBlob = await audioResponse.blob();
  
      const formData = new FormData();
      formData.append('audio', audioBlob, 'user_recording.webm');
      formData.append('musicid', uuid);
  
      const res = await fetch('http://172.20.12.58:80/autotune_vocal', {
        method: 'POST',
        body: formData,
      });

      console.log("res", res);
  
      if (res.ok) {
        const tunedBlob = await res.blob();
        const tunedUrl = URL.createObjectURL(tunedBlob);
        setTunedAudioUrl(tunedUrl);
      } else {
        alert('ì˜¤í† íŠ  ì²˜ë¦¬ ì‹¤íŒ¨');
      }
    } catch (err) {
      console.error('ì—ì½” ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', err);
      alert('ì—ì½” ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const playMergedTuned = () => {
    if (!audioUrl || !tunedAudioUrl) return;

    if (mrAudioRef.current && tunedAudioRef.current) {
      // ì •ì§€
      setTunedRecordPlaying(false);
      mrAudioRef.current.pause();
      mrAudioRef.current.currentTime = 0;
      mrAudioRef.current = null;
      tunedAudioRef.current.pause();
      tunedAudioRef.current.currentTime = 0;
      tunedAudioRef.current = null;
      return;
    }
  
    setTunedRecordPlaying(true);
    const mrAudio = new Audio(audioUrl);
    const tunedAudio = new Audio(tunedAudioUrl);
    mrAudio.volume = 0.6;
    tunedAudio.volume = 1.0;
    mrAudio.play();
    tunedAudio.play();
  
    mrAudioRef.current = mrAudio;
    tunedAudioRef.current = tunedAudio;
  };
  

  const playMergedEchoed = () => {
    if (!audioUrl || !echoedAudioUrl) return;

    if (mrAudioRef.current && echoedAudioRef.current) {
      // ì •ì§€
      setEchoedRecordPlaying(false);
      mrAudioRef.current.pause();
      mrAudioRef.current.currentTime = 0;
      echoedAudioRef.current.pause();
      echoedAudioRef.current.currentTime = 0;
      mrAudioRef.current = null;
      echoedAudioRef.current = null;
      return;
    }
  
    setEchoedRecordPlaying(true);
    const mrAudio = new Audio(audioUrl);
    const echoAudio = new Audio(echoedAudioUrl);
    mrAudio.volume = 0.6;
    echoAudio.volume = 1.0;
  
    mrAudio.play();
    echoAudio.play();
  
    mrAudioRef.current = mrAudio;
    echoedAudioRef.current = echoAudio;
  };

  // const analyzePitch = () => {
  //   const cleaned = pitchDataRef.current.filter(
  //     (p) => p !== null && p > 50 && p < 800
  //   ) as number[];
  //   const average =
  //   cleaned.reduce((a, b) => a + b, 0) / cleaned.length || 0;
  //   const variance =
  //   cleaned.reduce((acc, p) => acc + Math.pow(p - average, 2), 0) /
  //   cleaned.length || 0;
    
  //   const result: string[] = [];
  //   if (average > 500)
  //     result.push('âš ï¸ ì „ë°˜ì ìœ¼ë¡œ ê³ ìŒ ìœ„ì£¼ì…ë‹ˆë‹¤. ì•ˆì •ì ì¸ ë°œì„±ì´ í•„ìš”í•´ìš”.');
  //   if (variance > 2000)
  //     result.push('ğŸ¯ ìŒì • í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤. ë°œì„±ì˜ ì¼ê´€ì„±ì„ ì—°ìŠµí•´ë³´ì„¸ìš”.');
  //   if (average < 200)
  //     result.push('ğŸ“‰ ìŒì •ì´ ë‚®ì€ í¸ì…ë‹ˆë‹¤. ë” ì •í™•í•œ ìŒì •ì„ ê²¨ëƒ¥í•´ë³´ì„¸ìš”.');
    
  //   setFeedback(result);
  //   setAnalyzed(true);
  // };

  // console.log('UserRecord mounted with uuid:', uuid, 'audioUrl:', audioUrl);

  // í˜„ì¬ ì˜¤ë””ì˜¤ ì‹œê°„ì— ë§ì¶° ê°€ì‚¬ ì—…ë°ì´íŠ¸
  useEffect(() => {
    const interval = setInterval(() => {
      if (!audioRef.current) return;
  
      const currentTime = audioRef.current.currentTime;
      const current = lyricsRef.current.find(
        (line) =>
          currentTime >= line.start &&
          currentTime <= line.start + line.duration
      );
  
      setCurrentLyric(current?.text ?? '');
    }, 100); // 100ms ë‹¨ìœ„ë¡œ í™•ì¸
  
    return () => clearInterval(interval);
  }, []);

  return (
    <div>
    {userAudioUrl && (
      <div className="flex flex-col gap-2">
        <Card title="ğŸ™ ìœ ì € ë…¹ìŒ í™•ì¸">
          <Button
            type="default"
            size="large"
            style={{ width: 180}}
            icon={userRecordPlaying ? <PauseCircleOutlined /> : <PlayCircleOutlined />}
            onClick={playMergedAudio}
          >
            {userRecordPlaying ? 'ë…¹ìŒ ì •ì§€' : 'MR + ë…¹ìŒ ì¬ìƒ'}
          </Button>
        </Card>

        <Card title="ğŸ›ï¸ í›„ì²˜ë¦¬ íš¨ê³¼ ì„ íƒ">
          <Select
            value={selectedEffect}
            placeholder="ì ìš©í•  íš¨ê³¼ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            style={{ width: 180, marginRight: "8px" }}
            size="large"
            loading={loadingEffect}
            onChange={async (value: 'echo' | 'autotune') => {
              setSelectedEffect(value);
              setLoadingEffect(true);
              try {
                if (value === 'echo') {
                  await handleAddEcho();
                } else {
                  await handleAutoTune();
                }
              } catch (err) {
                console.error(err);
              } finally {
                setLoadingEffect(false);
              }
            }}
          >
            <Option value="echo">âœ¨ ì—ì½” ì¶”ê°€</Option>
            <Option value="autotune">ğŸ¤– ì˜¤í† íŠ </Option>
          </Select>
          {selectedEffect === 'echo' && echoedAudioUrl && (
            <Button
              type="default"
              size="large"
              icon={echoedRecordPlaying ? <PauseCircleOutlined /> : <SoundOutlined />}
              onClick={playMergedEchoed}
            >
              {echoedRecordPlaying ? 'ì •ì§€' : 'ì¬ìƒ'}
            </Button>
          )}
          {selectedEffect === 'autotune' && tunedAudioUrl && (
            <Button
              type="default"
              size="large"
              icon={tunedRecordPlaying ? <PauseCircleOutlined /> : <RobotOutlined />}
              onClick={playMergedTuned}
            >
              {tunedRecordPlaying ? 'ì •ì§€' : 'ì¬ìƒ'}
            </Button>
          )}
        </Card>
      </div>
    )}
  </div>
  );
}
